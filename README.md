# SpeechEmotionRecognition
#Overview
<br/>
This project implements Speech Emotion Recognition (SER) using Artificial Neural Networks (ANN) and Mel-Frequency Cepstral Coefficients (MFCCs) as features.
<br/>
The workflow involves:
<br/>
Feature Extraction from audio files (MFCCs)
<br/>
Model Training using a neural network
<br/>
Model Evaluation to assess performance
<br/>
Emotion Prediction from new audio samples
<br/>
#Model Details
<br/>
Uses ANN with 3 layers
<br/>
Activation: ReLU, Softmax
<br/>
Accuracy: ~85-90% (depends on dataset and training settings)
<br/>
#Next Steps
<br/>
Improve accuracy using CNNs or LSTMs
<br/>
Deploy model as a Web API using FastAPI
<br/>
Implement real-time emotion detection
